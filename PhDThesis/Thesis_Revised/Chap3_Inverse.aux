\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Inverse Problem}{27}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter3}{{3}{27}{Inverse Problem}{chapter.3}{}}
\newlabel{GenMinProb}{{3.1}{27}{Inverse Problem}{equation.3.0.1}{}}
\newlabel{eq:misfit}{{3.2}{27}{Inverse Problem}{equation.3.0.2}{}}
\newlabel{intSmall}{{3.3}{28}{Inverse Problem}{equation.3.0.3}{}}
\newlabel{fj}{{3.4}{28}{Inverse Problem}{equation.3.0.4}{}}
\newlabel{leastSquaresLin}{{3.5}{28}{Inverse Problem}{equation.3.0.5}{}}
\citation{HestenesStiefel1952,NocedalWright99}
\citation{LelievreOldenburgWilliams09}
\citation{LiDWO2000,PhDLelievre09}
\citation{Phillips1996,Williams08,Bosh2001,Fullagar2008}
\newlabel{volumeAve}{{3.7}{29}{Inverse Problem}{equation.3.0.7}{}}
\newlabel{lengthScale}{{3.8}{29}{Inverse Problem}{equation.3.0.8}{}}
\newlabel{gradPhi}{{3.9}{29}{Inverse Problem}{equation.3.0.9}{}}
\@writefile{brf}{\backcite{HestenesStiefel1952}{{29}{3}{equation.3.0.9}}}
\@writefile{brf}{\backcite{NocedalWright99}{{29}{3}{equation.3.0.9}}}
\@writefile{brf}{\backcite{LelievreOldenburgWilliams09}{{29}{3}{equation.3.0.9}}}
\@writefile{brf}{\backcite{PhDLelievre09}{{29}{3}{equation.3.0.9}}}
\@writefile{brf}{\backcite{LiDWO2000}{{29}{3}{equation.3.0.9}}}
\@writefile{brf}{\backcite{Bosh2001}{{29}{3}{equation.3.0.9}}}
\@writefile{brf}{\backcite{Fullagar2008}{{29}{3}{equation.3.0.9}}}
\@writefile{brf}{\backcite{Phillips1996}{{29}{3}{equation.3.0.9}}}
\@writefile{brf}{\backcite{Williams08}{{29}{3}{equation.3.0.9}}}
\citation{LiOldenburg1996}
\citation{Haber1997}
\citation{LiOldenburg1996}
\@writefile{toc}{\contentsline {subsubsection}{Sensitivity weighting}{30}{subsubsection*.22}}
\@writefile{brf}{\backcite{LiOldenburg1996}{{30}{3}{subsubsection*.22}}}
\newlabel{Jk}{{3.10}{30}{Sensitivity weighting}{equation.3.0.10}{}}
\@writefile{brf}{\backcite{Haber1997}{{30}{3}{equation.3.0.10}}}
\newlabel{iter_sens_weight}{{3.11}{30}{Sensitivity weighting}{equation.3.0.11}{}}
\newlabel{sensWAve}{{3.12}{30}{Sensitivity weighting}{equation.3.0.12}{}}
\citation{Huber64}
\@writefile{brf}{\backcite{LiOldenburg1996}{{31}{3}{equation.3.0.12}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.1}Synthetic gravity example}{31}{subsection.3.0.1}}
\newlabel{gravLineObjFun}{{3.13}{31}{Synthetic gravity example}{equation.3.0.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces (a) Vertical section through a 25 m cube with density $\rho $=0.2 g/cc placed in a uniform zero density background. (b) Simulated gravity data responses on a $21 \times 21$ survey grid placed 5 m above the flat topography. (c) Gravity data with random Gaussian noise added, $10^{-3}$ mGal standard deviation.\relax }}{32}{figure.caption.23}}
\newlabel{GRAV_model}{{3.1}{32}{(a) Vertical section through a 25 m cube with density $\rho $=0.2 g/cc placed in a uniform zero density background. (b) Simulated gravity data responses on a $21 \times 21$ survey grid placed 5 m above the flat topography. (c) Gravity data with random Gaussian noise added, $10^{-3}$ mGal standard deviation.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces (a) Vertical section through the inverted density model using the conventional $\ell _2$-norm regularization, (b) predicted and (c) normalized data residual. Outline of the true model (red) is shown for reference.\relax }}{33}{figure.caption.24}}
\newlabel{Grav_l2model}{{3.2}{33}{(a) Vertical section through the inverted density model using the conventional $\ell _2$-norm regularization, (b) predicted and (c) normalized data residual. Outline of the true model (red) is shown for reference.\relax }{figure.caption.24}{}}
\citation{Ekblom73}
\citation{Li93,Gorodnitsky97,FarquharsonOldenburg98,Daubechies10,SunLi14}
\citation{Lawson61}
\citation{Portniaguine1999,LastKubik83,BarbosaSilva94,Ajo-Franklin07}
\citation{Lawson61}
\citation{Lawson61}
\citation{SunLi14}
\citation{Fournier2015}
\citation{SunLi14}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}General $\ell _p$-norm regularization}{34}{section.3.1}}
\@writefile{brf}{\backcite{Huber64}{{34}{3.1}{section.3.1}}}
\@writefile{brf}{\backcite{Ekblom73}{{34}{3.1}{section.3.1}}}
\newlabel{Ekblom}{{3.14}{34}{General $\ell _p$-norm regularization}{equation.3.1.14}{}}
\@writefile{brf}{\backcite{Daubechies10}{{34}{3.1}{equation.3.1.14}}}
\@writefile{brf}{\backcite{FarquharsonOldenburg98}{{34}{3.1}{equation.3.1.14}}}
\@writefile{brf}{\backcite{Gorodnitsky97}{{34}{3.1}{equation.3.1.14}}}
\@writefile{brf}{\backcite{Li93}{{34}{3.1}{equation.3.1.14}}}
\@writefile{brf}{\backcite{SunLi14}{{34}{3.1}{equation.3.1.14}}}
\@writefile{brf}{\backcite{Lawson61}{{34}{3.1}{equation.3.1.14}}}
\newlabel{eq:IntegralIRLS}{{3.15}{34}{General $\ell _p$-norm regularization}{equation.3.1.15}{}}
\@writefile{brf}{\backcite{Ajo-Franklin07}{{34}{3.1}{equation.3.1.15}}}
\@writefile{brf}{\backcite{BarbosaSilva94}{{34}{3.1}{equation.3.1.15}}}
\@writefile{brf}{\backcite{LastKubik83}{{34}{3.1}{equation.3.1.15}}}
\@writefile{brf}{\backcite{Portniaguine1999}{{34}{3.1}{equation.3.1.15}}}
\@writefile{brf}{\backcite{SunLi14}{{34}{3.1}{figure.caption.25}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Approximated $\ell _p$-norm using the Lawson measure \cite  []{Lawson61} over a range of $p$-values and for a fixed threshold parameter $\epsilon =10^{-1}$.\relax }}{35}{figure.caption.25}}
\@writefile{brf}{\backcite{Lawson61}{{35}{3.3}{figure.caption.25}}}
\newlabel{NormIRLS}{{3.3}{35}{Approximated $\ell _p$-norm using the Lawson measure \cite []{Lawson61} over a range of $p$-values and for a fixed threshold parameter $\epsilon =10^{-1}$.\relax }{figure.caption.25}{}}
\@writefile{brf}{\backcite{Fournier2015}{{35}{3.1}{figure.caption.25}}}
\@writefile{brf}{\backcite{SunLi14}{{35}{3.1}{figure.caption.25}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Synthetic 1D problem}{35}{subsection.3.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Linear forward problem made up of: (a) an example kernel function ; (b) model; (c) observed data with assigned standard errors.\relax }}{36}{figure.caption.26}}
\newlabel{Problem1D}{{3.4}{36}{Linear forward problem made up of: (a) an example kernel function ; (b) model; (c) observed data with assigned standard errors.\relax }{figure.caption.26}{}}
\newlabel{Forward_Noisy}{{3.16}{36}{Synthetic 1D problem}{equation.3.1.16}{}}
\newlabel{1DLineObjFun}{{3.17}{36}{Synthetic 1D problem}{equation.3.1.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Solution to the 1D inverse problem using (a) an $\ell _2$-norm on the model ($\alpha _x = 0$), (b) the $\ell _2$-norm on model gradients ($\alpha _s=0$) and (c) combined regularization function ($\alpha _s=2500,\tmspace  +\thickmuskip {.2777em}\alpha _x = 1$). (d) Convergence curve comparing the misfit ($\phi _d$) and the regularization ($\phi _m$) as a function of iterations. (e) Comparative plot for the relative contribution of the different components of the objective function measured in terms of maximum absolute gradient ($\left \delimiter "026B30D  \mathbf  {g}_i \right \delimiter "026B30D _\infty $)\relax }}{37}{figure.caption.27}}
\newlabel{Problem1D_l2Result}{{3.5}{37}{Solution to the 1D inverse problem using (a) an $\ell _2$-norm on the model ($\alpha _x = 0$), (b) the $\ell _2$-norm on model gradients ($\alpha _s=0$) and (c) combined regularization function ($\alpha _s=2500,\;\alpha _x = 1$). (d) Convergence curve comparing the misfit ($\phi _d$) and the regularization ($\phi _m$) as a function of iterations. (e) Comparative plot for the relative contribution of the different components of the objective function measured in terms of maximum absolute gradient ($\left \| \mathbf {g}_i \right \|_\infty $)\relax }{figure.caption.27}{}}
\newlabel{derivRatio}{{3.19}{38}{Synthetic 1D problem}{equation.3.1.19}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Norm values and proportionality ratio obtained for the 1D solution presented in Figure\nobreakspace  {}\ref  {Problem1D_l2Result}(c). A proportionality ratio of $\lambda _\infty \approx 1$ indicates that the components of the regularization function are both contributing significantly to the final solution.\relax }}{39}{table.caption.28}}
\newlabel{PropRatio}{{3.1}{39}{Norm values and proportionality ratio obtained for the 1D solution presented in Figure~\ref {Problem1D_l2Result}(c). A proportionality ratio of $\lambda _\infty \approx 1$ indicates that the components of the regularization function are both contributing significantly to the final solution.\relax }{table.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Iterative Re-weighted Least Squares algorithm}{39}{subsection.3.1.2}}
\newlabel{eq:lpreg}{{3.20}{39}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.20}{}}
\newlabel{eq:IntegralIRLSLawson}{{3.21}{39}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.21}{}}
\newlabel{eq:IRLS_fm}{{3.22}{39}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.22}{}}
\newlabel{eq:IRLS}{{3.23}{40}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.23}{}}
\newlabel{IRLSphis}{{3.24}{40}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.24}{}}
\newlabel{eq:R_w}{{3.25}{40}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.25}{}}
\newlabel{eq:IRLSderiv}{{3.26}{40}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.26}{}}
\newlabel{phixMatrix}{{3.27}{40}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.27}{}}
\newlabel{1D_Grad}{{3.28}{40}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.28}{}}
\citation{HestenesStiefel1952}
\citation{NocedalWright99}
\newlabel{eq:Rx_w}{{3.29}{41}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.29}{}}
\newlabel{IRLSobjFun}{{3.30}{41}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.30}{}}
\newlabel{Stage1}{{1}{41}{Iterative Re-weighted Least Squares algorithm}{Item.1}{}}
\newlabel{Stage2}{{2}{41}{Iterative Re-weighted Least Squares algorithm}{Item.2}{}}
\newlabel{GaussNewtStep}{{3.31}{41}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.31}{}}
\@writefile{brf}{\backcite{HestenesStiefel1952}{{41}{2}{equation.3.1.31}}}
\newlabel{GNmodelUpdate}{{3.32}{41}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.32}{}}
\@writefile{brf}{\backcite{NocedalWright99}{{41}{3.1.2}{equation.3.1.32}}}
\citation{Osborne1985,Daubechies10}
\citation{Scipy2001}
\newlabel{phidTol}{{3.33}{42}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.33}{}}
\newlabel{phimTol}{{3.34}{42}{Iterative Re-weighted Least Squares algorithm}{equation.3.1.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Case 1: $\ell _1$-norm ($p_s=p_x=1$)}{42}{subsection.3.1.3}}
\newlabel{l1norm}{{3.1.3}{42}{Case 1: $\ell _1$-norm ($p_s=p_x=1$)}{subsection.3.1.3}{}}
\@writefile{brf}{\backcite{Daubechies10}{{42}{3.1.3}{subsection.3.1.3}}}
\@writefile{brf}{\backcite{Osborne1985}{{42}{3.1.3}{subsection.3.1.3}}}
\@writefile{brf}{\backcite{Scipy2001}{{42}{3.1.3}{subsection.3.1.3}}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces IRLS algorithm in pseudo-code made of two stages: Stage\nobreakspace  {}\ref  {Stage1} Initialization with convex least-squares inversion, Stage\nobreakspace  {}\ref  {Stage2} IRLS updates with inner $\beta $-search steps.\relax }}{43}{table.caption.29}}
\newlabel{IRLSalgo}{{3.2}{43}{IRLS algorithm in pseudo-code made of two stages: Stage~\ref {Stage1} Initialization with convex least-squares inversion, Stage~\ref {Stage2} IRLS updates with inner $\beta $-search steps.\relax }{table.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces (a) Two solutions using an $\ell _1$-norm on the model: (blue) Simplex, and (black) IRLS method. (b) Solution obtained with the approximated $\ell _1$-norm (IRLS) penalty on model gradients alone and (c) with the combined penalty functions ($\alpha _s=2500,\tmspace  +\thickmuskip {.2777em}\alpha _x = 1$). The calculated proportionality ratio $\lambda _\infty $ indicates that the combined penalties is dominated by the $\phi _s^1$ term. (d) Convergence curve and (e) maximum partial derivatives associated with the components of the objective function as a function of iterations for the inversion in (c). The vertical dotted lines indicate the change in regularization from an $\ell _2$-norm to $\ell _1$-norm measure.\relax }}{44}{figure.caption.30}}
\newlabel{Problem1D_l1Result}{{3.6}{44}{(a) Two solutions using an $\ell _1$-norm on the model: (blue) Simplex, and (black) IRLS method. (b) Solution obtained with the approximated $\ell _1$-norm (IRLS) penalty on model gradients alone and (c) with the combined penalty functions ($\alpha _s=2500,\;\alpha _x = 1$). The calculated proportionality ratio $\lambda _\infty $ indicates that the combined penalties is dominated by the $\phi _s^1$ term. (d) Convergence curve and (e) maximum partial derivatives associated with the components of the objective function as a function of iterations for the inversion in (c). The vertical dotted lines indicate the change in regularization from an $\ell _2$-norm to $\ell _1$-norm measure.\relax }{figure.caption.30}{}}
\newlabel{eq:IRLSderivFactored}{{3.35}{45}{Case 1: $\ell _1$-norm ($p_s=p_x=1$)}{equation.3.1.35}{}}
\newlabel{lengthScaleLp}{{3.36}{45}{Case 1: $\ell _1$-norm ($p_s=p_x=1$)}{equation.3.1.36}{}}
\citation{LastKubik83}
\citation{PortniaguineZhdanov02}
\citation{BarbosaSilva94,Chartrand07,Ajo-Franklin07,Blaschek2008,Stocco09}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces (a) Solution obtained with the combined penalty functions $\alpha _s \phi _s^1 + \alpha _x \phi _x^1$ after re-adjustment of $\alpha _s=50,\tmspace  +\thickmuskip {.2777em}\alpha _x = 1$. (b) Convergence curve and (c) maximum partial derivatives associated with the components of the objective function as a function of iteration.\relax }}{46}{figure.caption.31}}
\newlabel{Problem1D_l1l1}{{3.7}{46}{(a) Solution obtained with the combined penalty functions $\alpha _s \phi _s^1 + \alpha _x \phi _x^1$ after re-adjustment of $\alpha _s=50,\;\alpha _x = 1$. (b) Convergence curve and (c) maximum partial derivatives associated with the components of the objective function as a function of iteration.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Case 2: $\ell _0$-norm ($p_s=p_x=0$)}{46}{subsection.3.1.4}}
\@writefile{brf}{\backcite{LastKubik83}{{46}{3.1.4}{subsection.3.1.4}}}
\@writefile{brf}{\backcite{PortniaguineZhdanov02}{{46}{3.1.4}{subsection.3.1.4}}}
\@writefile{brf}{\backcite{Ajo-Franklin07}{{46}{3.1.4}{subsection.3.1.4}}}
\@writefile{brf}{\backcite{BarbosaSilva94}{{46}{3.1.4}{subsection.3.1.4}}}
\@writefile{brf}{\backcite{Blaschek2008}{{46}{3.1.4}{subsection.3.1.4}}}
\@writefile{brf}{\backcite{Chartrand07}{{46}{3.1.4}{subsection.3.1.4}}}
\@writefile{brf}{\backcite{Stocco09}{{46}{3.1.4}{subsection.3.1.4}}}
\citation{SunLi14}
\citation{Fournier2015}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Solution to the 1D inverse problem using an approximate $\ell _0$-norm (a) on the model, (b) on model gradients and (c) combined penalty functions using the IRLS algorithm ($\alpha _s=1,\tmspace  +\thickmuskip {.2777em}\alpha _x = 1$). All three solutions honor the data within the target misfit $\phi _d^*$.\relax }}{47}{figure.caption.32}}
\newlabel{Problem1D_l0Result}{{3.8}{47}{Solution to the 1D inverse problem using an approximate $\ell _0$-norm (a) on the model, (b) on model gradients and (c) combined penalty functions using the IRLS algorithm ($\alpha _s=1,\;\alpha _x = 1$). All three solutions honor the data within the target misfit $\phi _d^*$.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Mixed norm regularization}{47}{section.3.2}}
\@writefile{brf}{\backcite{SunLi14}{{47}{3.2}{section.3.2}}}
\@writefile{brf}{\backcite{Fournier2015}{{48}{3.2}{section.3.2}}}
\newlabel{mixNorm}{{3.37}{48}{Mixed norm regularization}{equation.3.2.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Scaled-IRLS steps}{48}{subsection.3.2.1}}
\newlabel{eq:IRLS_Grad_genericMat}{{3.38}{48}{Scaled-IRLS steps}{equation.3.2.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces (a) Recovered model and (b) convergence curves using the conventional IRLS method for $p_s=0,\tmspace  +\thickmuskip {.2777em}p_x=2$ and a fixed threshold parameter $\epsilon =10^{-3}$ ($\alpha _s=\alpha _x=1$). (c) Trade-off parameter and maximum gradients for the different components of the objective function. At the start of Stage\nobreakspace  {}\ref  {Stage2} (iteration 6), the sudden increase in $\left \delimiter "026B30D  \mathbf  {g}_s \right \delimiter "026B30D _\infty $ is matched with a decrease in $\beta $. Throughout the inversion, $\left \delimiter "026B30D  \mathbf  {g}_x \right \delimiter "026B30D _\infty $ remains small in magnitude. \relax }}{49}{figure.caption.33}}
\newlabel{Mixed1DnoEta}{{3.9}{49}{(a) Recovered model and (b) convergence curves using the conventional IRLS method for $p_s=0,\;p_x=2$ and a fixed threshold parameter $\epsilon =10^{-3}$ ($\alpha _s=\alpha _x=1$). (c) Trade-off parameter and maximum gradients for the different components of the objective function. At the start of Stage~\ref {Stage2} (iteration 6), the sudden increase in $\left \| \mathbf {g}_s \right \|_\infty $ is matched with a decrease in $\beta $. Throughout the inversion, $\left \| \mathbf {g}_x \right \|_\infty $ remains small in magnitude. \relax }{figure.caption.33}{}}
\newlabel{gammaScale}{{3.39}{49}{Scaled-IRLS steps}{equation.3.2.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Derivatives of the Lawson approximation over a range of model values for (a) a fixed threshold parameter $\epsilon =10^{-1}$ over a range of $p$ values and for (b) a fixed $p=0$ over a range of $\epsilon $ values. (c) Applying the $\gamma $-scaling to the gradients brings all maximums to be equal irrespective of $p$ and $\epsilon $.\relax }}{50}{figure.caption.34}}
\newlabel{NormDeriv}{{3.10}{50}{Derivatives of the Lawson approximation over a range of model values for (a) a fixed threshold parameter $\epsilon =10^{-1}$ over a range of $p$ values and for (b) a fixed $p=0$ over a range of $\epsilon $ values. (c) Applying the $\gamma $-scaling to the gradients brings all maximums to be equal irrespective of $p$ and $\epsilon $.\relax }{figure.caption.34}{}}
\newlabel{mMaxGrad}{{3.41}{50}{Scaled-IRLS steps}{equation.3.2.41}{}}
\newlabel{etaScale}{{3.42}{51}{Scaled-IRLS steps}{equation.3.2.42}{}}
\newlabel{gamma_s}{{3.43}{51}{Scaled-IRLS steps}{equation.3.2.43}{}}
\@writefile{toc}{\contentsline {subsubsection}{Scaled model derivatives}{51}{subsubsection*.36}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces (a) Recovered model and (b) convergence curves using the Scaled-IRLS approach for $p_s=0,\tmspace  +\thickmuskip {.2777em}p_x=2$ and a fixed threshold parameter $\epsilon =1e-3$ ($\alpha _s=\alpha _x=1$). (c) Trade-off parameter and maximum gradients for the different components of the objective function. The scaling procedures preserves the proportionality between $\left \delimiter "026B30D  \mathbf  {g}^{p_s}_s \right \delimiter "026B30D _\infty $ and $\left \delimiter "026B30D  \mathbf  {g}^{p_x}_x \right \delimiter "026B30D _\infty $ throughout the iteration process. The trade-off $\beta $-parameter needed only to be adjusted slightly at the beginning of Stage\nobreakspace  {}\ref  {Stage2}. \relax }}{52}{figure.caption.35}}
\newlabel{Mixed1DnotCooledEta}{{3.11}{52}{(a) Recovered model and (b) convergence curves using the Scaled-IRLS approach for $p_s=0,\;p_x=2$ and a fixed threshold parameter $\epsilon =1e-3$ ($\alpha _s=\alpha _x=1$). (c) Trade-off parameter and maximum gradients for the different components of the objective function. The scaling procedures preserves the proportionality between $\left \| \mathbf {g}^{p_s}_s \right \|_\infty $ and $\left \| \mathbf {g}^{p_x}_x \right \|_\infty $ throughout the iteration process. The trade-off $\beta $-parameter needed only to be adjusted slightly at the beginning of Stage~\ref {Stage2}. \relax }{figure.caption.35}{}}
\newlabel{gxlp}{{3.44}{52}{Scaled model derivatives}{equation.3.2.44}{}}
\newlabel{finiteDifference}{{3.45}{52}{Scaled model derivatives}{equation.3.2.45}{}}
\newlabel{gamma_x_nonscaled}{{3.48}{53}{Scaled model derivatives}{equation.3.2.48}{}}
\newlabel{phim_gamma}{{3.49}{53}{Scaled model derivatives}{equation.3.2.49}{}}
\newlabel{phim_alpha}{{3.50}{53}{Scaled model derivatives}{equation.3.2.50}{}}
\newlabel{etaScale}{{3.52}{54}{Scaled model derivatives}{equation.3.2.52}{}}
\newlabel{gammaScale}{{3.53}{54}{Scaled model derivatives}{equation.3.2.53}{}}
\newlabel{IRLSobjFunScaled}{{3.54}{54}{Scaled model derivatives}{equation.3.2.54}{}}
\citation{LastKubik83}
\citation{BarbosaSilva94,Stocco09}
\citation{Ajo-Franklin07}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Recovered 1D models for $p_s=p_x=1$ using different scaling strategies and parameterization. (a) Solution previously shown in Figure\nobreakspace  {}\ref  {Problem1D_l1l1} that uses the standard gradient measure ($\alpha _s$=50). (b) Solution obtained with the finite difference approach ($\alpha _s=\alpha _x=1$). (c) Model recovered with a different parameterization such that the right half of the domain has cells with half the size. Small discrepancies between the three solutions can be attributed to slight differences in the iterative process. \relax }}{55}{figure.caption.37}}
\newlabel{Mixed1D_p1_normalizedTest}{{3.12}{55}{Recovered 1D models for $p_s=p_x=1$ using different scaling strategies and parameterization. (a) Solution previously shown in Figure~\ref {Problem1D_l1l1} that uses the standard gradient measure ($\alpha _s$=50). (b) Solution obtained with the finite difference approach ($\alpha _s=\alpha _x=1$). (c) Model recovered with a different parameterization such that the right half of the domain has cells with half the size. Small discrepancies between the three solutions can be attributed to slight differences in the iterative process. \relax }{figure.caption.37}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Components of the objective function corresponding to the inversion results presented in Figure\nobreakspace  {}\ref  {Mixed1D_p1_normalizedTest} for $p_s=p_x=1$. \relax }}{55}{table.caption.38}}
\newlabel{IRLS_ScalingTest}{{3.3}{55}{Components of the objective function corresponding to the inversion results presented in Figure~\ref {Mixed1D_p1_normalizedTest} for $p_s=p_x=1$. \relax }{table.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Threshold $\epsilon $-parameter}{55}{subsection.3.2.2}}
\@writefile{brf}{\backcite{LastKubik83}{{55}{3.2.2}{subsection.3.2.2}}}
\@writefile{brf}{\backcite{BarbosaSilva94}{{55}{3.2.2}{subsection.3.2.2}}}
\@writefile{brf}{\backcite{Stocco09}{{55}{3.2.2}{subsection.3.2.2}}}
\@writefile{brf}{\backcite{Ajo-Franklin07}{{55}{3.2.2}{subsection.3.2.2}}}
\citation{SunLi14}
\citation{ZhdanovTolstaya2004}
\@writefile{brf}{\backcite{SunLi14}{{56}{3.2.2}{subsection.3.2.2}}}
\@writefile{brf}{\backcite{ZhdanovTolstaya2004}{{56}{3.2.2}{subsection.3.2.2}}}
\newlabel{CoolingRate}{{3.55}{56}{Threshold $\epsilon $-parameter}{equation.3.2.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Recovered 1D models with variable threshold parameter on the range $10^{-5} < \epsilon < 10^{0}$ using a mixed-norm penalty function $\phi _m = \alpha _s\phi ^0_s + \alpha _x\phi ^2_x$. \relax }}{57}{figure.caption.39}}
\newlabel{Mixed1DnotCooledEps}{{3.13}{57}{Recovered 1D models with variable threshold parameter on the range $10^{-5} < \epsilon < 10^{0}$ using a mixed-norm penalty function $\phi _m = \alpha _s\phi ^0_s + \alpha _x\phi ^2_x$. \relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces (a)-(d) Recovered 1D models at different iteration steps $(k)$. The value of $\epsilon $ (dash) is shown for reference, highlighting the idea of a progressive thresholding of model values. (e) Scaled partial derivatives ($\gamma ^2 \mathbf  {g}_s^0$) as a function of the sorted model values and at various iteration stages. \relax }}{58}{figure.caption.40}}
\newlabel{Mixed1DIterates}{{3.14}{58}{(a)-(d) Recovered 1D models at different iteration steps $(k)$. The value of $\epsilon $ (dash) is shown for reference, highlighting the idea of a progressive thresholding of model values. (e) Scaled partial derivatives ($\gamma ^2 \mathbf {g}_s^0$) as a function of the sorted model values and at various iteration stages. \relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Partial derivatives of the objective function for iteration (top) k=15 and (bottom) k=55. The recovered models are shown in red for reference. \relax }}{59}{figure.caption.41}}
\newlabel{Problem1D_CooledEta_dphi}{{3.15}{59}{Partial derivatives of the objective function for iteration (top) k=15 and (bottom) k=55. The recovered models are shown in red for reference. \relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces (a-d) Recovered models and (e) convergence curves for the minimization of $\phi _d +\beta \phi _m^p$ with various cooling rates $\eta $ but with a final $\epsilon ^* = 1e-6$. \relax }}{59}{figure.caption.42}}
\newlabel{Mixed1DCooledEta}{{3.16}{59}{(a-d) Recovered models and (e) convergence curves for the minimization of $\phi _d +\beta \phi _m^p$ with various cooling rates $\eta $ but with a final $\epsilon ^* = 1e-6$. \relax }{figure.caption.42}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Inversion summary after convergence of the S-IRLS for various cooling rates $\eta $ as presented in Figure\nobreakspace  {}\ref  {Mixed1DCooledEta}. Each inversion trial was required to reach the target misfit $\phi _d^*$ and target $\epsilon ^* = 1e-6$ .\relax }}{60}{table.caption.43}}
\newlabel{table:Cooling}{{3.4}{60}{Inversion summary after convergence of the S-IRLS for various cooling rates $\eta $ as presented in Figure~\ref {Mixed1DCooledEta}. Each inversion trial was required to reach the target misfit $\phi _d^*$ and target $\epsilon ^* = 1e-6$ .\relax }{table.caption.43}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Summary}{60}{subsection.3.2.3}}
\newlabel{eq:GeneralLPProblem}{{3.56}{61}{Summary}{equation.3.2.56}{}}
\newlabel{eq:LocalIRLS}{{3.57}{61}{Summary}{equation.3.2.57}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Exploring the model space}{61}{section.3.3}}
\newlabel{ObjFun3D}{{3.58}{62}{Exploring the model space}{equation.3.3.58}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Interpretation}{62}{subsection.3.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces (a-i) Vertical section through a suite of density models recovered for varying $\ell _p$-norm penalties applied on the model and model gradients for $p_s\in [0,\tmspace  +\medmuskip {.2222em}1,\tmspace  +\medmuskip {.2222em} 2]$ and $p_{x}=p_{y}=p_{z}\in [0,\tmspace  +\medmuskip {.2222em}1,\tmspace  +\medmuskip {.2222em} 2]$. \relax }}{63}{figure.caption.44}}
\newlabel{GravMixedNorms}{{3.17}{63}{(a-i) Vertical section through a suite of density models recovered for varying $\ell _p$-norm penalties applied on the model and model gradients for $p_s\in [0,\:1,\: 2]$ and $p_{x}=p_{y}=p_{z}\in [0,\:1,\: 2]$. \relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Iso-contour values for the $10^{th}$ and $90^{th}$ percentile of anomalous density calculated from the suite of models shown in Figure\nobreakspace  {}\ref  {GravMixedNorms}. The outline of the target (red) is shown for reference. Contour lines tightly clustered indicate coherence between inversion trials. Negative anomalies (dash) appear to change significantly, to which I would assign lower confidence. \relax }}{64}{figure.caption.45}}
\newlabel{GravMixedNormContours}{{3.18}{64}{Iso-contour values for the $10^{th}$ and $90^{th}$ percentile of anomalous density calculated from the suite of models shown in Figure~\ref {GravMixedNorms}. The outline of the target (red) is shown for reference. Contour lines tightly clustered indicate coherence between inversion trials. Negative anomalies (dash) appear to change significantly, to which I would assign lower confidence. \relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces (a-i) Residual data map calculated from the suite of density models for varying $\ell _p$-norm penalties applied on the model and model gradients for $p_s\in [0,\tmspace  +\medmuskip {.2222em}1,\tmspace  +\medmuskip {.2222em} 2]$ and $p_{x}=p_{y}=p_{z}\in [0,\tmspace  +\medmuskip {.2222em}1,\tmspace  +\medmuskip {.2222em} 2]$. \relax }}{65}{figure.caption.46}}
\newlabel{GravMixedNorms_dpred}{{3.19}{65}{(a-i) Residual data map calculated from the suite of density models for varying $\ell _p$-norm penalties applied on the model and model gradients for $p_s\in [0,\:1,\: 2]$ and $p_{x}=p_{y}=p_{z}\in [0,\:1,\: 2]$. \relax }{figure.caption.46}{}}
\@setckpt{Chap3_Inverse}{
\setcounter{page}{66}
\setcounter{equation}{58}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{3}
\setcounter{subsection}{1}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{19}
\setcounter{table}{4}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{1}
\setcounter{NAT@ctr}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{Item}{2}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{33}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{0}
}
